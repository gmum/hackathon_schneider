{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import load_data\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the original dataset\n",
    "df = load_data('../data')\n",
    "#mapping AreaID values to their meaning\n",
    "#load the dictionary\n",
    "AreaID_dict = \"../data/AreaID_dict.json\"\n",
    "with open(AreaID_dict, 'r') as file:\n",
    "    AreaID_dict = json.load(file)\n",
    "\n",
    "#mapping the df\\\n",
    "df2 = df.copy()\n",
    "df2['AreaID'] = df2['AreaID'] f.map(AreaID_dict)\n",
    "df2['Country'] = df2['AreaID'].str.extract(r'\\\\((.*?)\\\\)')\n",
    "# Drop the original 'AreaID' column\n",
    "df2.drop('AreaID', axis=1, inplace=True)\n",
    "#dropping 'UnitName' as it's useless and rearranging the columns\\\n",
    "df3 = df2[['StartTime','EndTime','Country','PsrType','Load','quantity']]\n",
    "\n",
    "#Replace NaN values with 0\n",
    "df3[['Load', 'PsrType', 'quantity']] = df3[['Load', 'PsrType', 'quantity']].fillna(0)\n",
    "\n",
    "#Filtering by green_energy PsrType\n",
    "df3 = df3[df3['PsrType'].isin([\"B01\", \"B09\", \"B10\", \"B11\", \"B12\",\"B13\", \"B15\", \"B16\", \"B18\", \"B19\", 0])]\n",
    "df3.drop('PsrType', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORKING ON TIME COLUMNS \n",
    "#in order to do so we will separate Load and quantity into different dataframes (we'll rejoin them later)\n",
    "dfLoad = df3[['StartTime','EndTime','Country','Load']].groupby(['StartTime','EndTime','Country']).sum().reset_index()\n",
    "dfQuantity = df3[['StartTime','EndTime','Country','quantity']].groupby(['StartTime','EndTime','Country']).sum().reset_index()\n",
    "\n",
    "#function to simplify code\n",
    "def hourly_arrange(df0, metric):\n",
    "    # Convert to datetime\n",
    "    df0[\"StartTime\"] = pd.to_datetime(df0[\"StartTime\"], format=\"%Y-%m-%dT%H:%M%zZ\")\n",
    "    df0[\"EndTime\"] = pd.to_datetime(df0[\"EndTime\"], format=\"%Y-%m-%dT%H:%M%zZ\")\n",
    "\n",
    "    # Set the index to 'StartTime' or 'EndTime'\n",
    "    df0.set_index('StartTime', inplace=True)\n",
    "\n",
    "    # Create a new DataFrame for each Country to work the time rows separately and avoid the interpolate() function mix btween Countries\\\n",
    "    grouped = df0.groupby('Country')\n",
    "\n",
    "    # Resample and interpolate\\\n",
    "    resampled_dfs = []\n",
    "    for name, group in grouped:\n",
    "        # Resample to hourly frequency, interpolate, and sum Load values\\\n",
    "        resampled_df = group.resample('H').sum().interpolate()\n",
    "        \n",
    "        # Add the 'Country' information back to the resampled DataFrame\\\n",
    "        resampled_df['Country'] = name\n",
    "        \n",
    "        resampled_dfs.append(resampled_df)\n",
    "\n",
    "    # Concatenate the resampled DataFrames\\\n",
    "    df0= pd.concat(resampled_dfs).reset_index()\n",
    "\n",
    "    return df0\n",
    "#applying the function to dfLoad and dfQuantity\\\n",
    "dfLoad = hourly_arrange(dfLoad, 'Load')\n",
    "dfQuantity = hourly_arrange(dfQuantity, 'quantity')\n",
    "#merging dfLoad and dfQuantity dataframes\\\n",
    "df4 = pd.merge(dfLoad, dfQuantity, on=['StartTime', 'Country'], how='outer')\n",
    "df4.fillna(0, inplace=True)\n",
    "#rearranging and renaming columns\\\n",
    "df4 = df4[['StartTime','Country','Load','quantity']]\n",
    "df4.rename(columns={'Load':'load'}, inplace=True)\n",
    "dfLoad.info()\n",
    "dfQuantity.info()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
